{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekPa8BMs-VpQ"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai\n",
        "!pip install colorama\n",
        "!pip install google-cloud-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfIoG8o6QeBo"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/images_probe.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djv6rXrA-MWy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import concurrent.futures  # Import this to remove errors related to threading\n",
        "from Class_Google_Clould_Vision import Google_Cloud_Vision\n",
        "from Class_Logger import Logger\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from model import EnhancedCNN\n",
        "\n",
        "\n",
        "vision_path = \"\"\n",
        "model_name = \"gemini-2.0-flash-exp\"\n",
        "classifier_path = '/content/enhanced_cnn_best.pth'\n",
        "\n",
        "\n",
        "def load_api_keys(file_path):\n",
        "    keys = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"key\"):\n",
        "                parts = line.split(\":\", 1)\n",
        "                if len(parts) == 2:\n",
        "                    key = parts[1].strip()\n",
        "                    keys.append(key)\n",
        "    return keys\n",
        "\n",
        "\n",
        "api_key_file = \"/content/Api keys _ gemini_for_production.txt\"\n",
        "api_keys = load_api_keys(api_key_file)\n",
        "if not api_keys:\n",
        "    raise ValueError(\"No Gemini API keys found in the provided file.\")\n",
        "print(\"Modules Imported Successfully!!!!!\")\n",
        "\n",
        "token_usage_list = []  # Global list to store token usage\n",
        "failed_key_info = []  # global list to track failed keys\n",
        "\n",
        "# Load class names from the text file\n",
        "with open('/content/class_names.txt', 'r') as f:\n",
        "    class_names = [line.strip() for line in f.readlines()]\n",
        "\n",
        "\n",
        "# Function to perform inference on an image\n",
        "def predict_image(image_path, model_path, class_names, threshold=0.5):\n",
        "    # Instantiate the model and load the trained weights\n",
        "    model = EnhancedCNN(num_classes=len(class_names))\n",
        "    model.load_state_dict(\n",
        "        torch.load(\n",
        "            model_path,\n",
        "            map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "            weights_only=True\n",
        "        )\n",
        "    )\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Move model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Define the transformation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),  # Match input size during training\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)  # Forward pass\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Convert to probabilities\n",
        "        confidence, predicted = torch.max(probabilities, 1)  # Get the max probability and corresponding class index\n",
        "        predicted_class = predicted.item()\n",
        "        predicted_label = class_names[predicted_class]\n",
        "\n",
        "    # Check confidence level\n",
        "    if confidence.item() < threshold:\n",
        "        predicted_label = \"Unforeseen Image\"\n",
        "\n",
        "    return predicted_class, predicted_label, confidence.item()\n",
        "\n",
        "\n",
        "def generate_gemini_content(prompt, image_path, img_binary, model_name, active_api_key, logger_instance):\n",
        "    genai.configure(api_key=active_api_key)\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    try:\n",
        "        logger_instance.info(f\"Attempting Gemini API call with key: {active_api_key}\")\n",
        "        response = model.generate_content([prompt, image])\n",
        "        json_str = response.text.strip('```json').strip('```')\n",
        "\n",
        "        processed_results = []\n",
        "        # attempt to extract the valid dict from the JSON\n",
        "        for match in re.finditer(r'{[^{}]*}', json_str):\n",
        "            try:\n",
        "                item = json.loads(match.group(0))\n",
        "                if all(key in item for key in [\"Given_Name\", \"Surname\", \"Occupation\", \"Date\", \"bounding_box\", \"confidence\"]):\n",
        "                    bounding_box = item.get('bounding_box')  # safely access bounding_box\n",
        "                    if isinstance(bounding_box, str):\n",
        "                        try:\n",
        "                            x1, y1, x2, y2 = map(int, bounding_box.split(','))\n",
        "                            cv2.rectangle(img_binary, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 1)\n",
        "                        except ValueError:\n",
        "                            print(f\"Warning: Could not parse bounding box for record:{item}, skipping bbox drawing\")\n",
        "                    elif isinstance(bounding_box, list) and len(bounding_box) == 4:\n",
        "                        x1, y1, x2, y2 = map(int, bounding_box)\n",
        "                        cv2.rectangle(img_binary, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 1)\n",
        "                    else:\n",
        "                        print(\n",
        "                            f\"Warning: Invalid bounding box format or missing data for record:{item}, skipping bbox drawing\")\n",
        "\n",
        "                    item['Image'] = os.path.basename(image_path)  # adding the image key\n",
        "                    processed_results.append(item)\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"JSONDecodeError while parsing partial JSON from Gemini response\")\n",
        "                continue\n",
        "\n",
        "        cv2.imwrite(os.path.join('output_images', os.path.basename(image_path)), img_binary)\n",
        "\n",
        "        global token_usage_list\n",
        "        # Add token count to global list\n",
        "        token_usage_list.append({\n",
        "            'Image': os.path.basename(image_path),\n",
        "            'Tokens_used': response.usage_metadata.total_token_count\n",
        "        })\n",
        "        return processed_results, True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger_instance.error(f\"An Error occurred during the process, with error {e} with key: {active_api_key}\")\n",
        "        return None, False\n",
        "\n",
        "\n",
        "def extract_table_rows_with_vision_data_v2(image_path, vision_response, img_binary, model_name, api_keys,\n",
        "                                          logger_instance, key_index):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        Analyze the following image and the provided text data:\n",
        "\n",
        "        **Image:**\n",
        "        [Image of {image_path}]\n",
        "\n",
        "        **Text Data:**\n",
        "        {json.dumps(vision_response, indent=2)}\n",
        "\n",
        "        **Task:**\n",
        "        1. Given_Name: The full first name(s) of the individual. It can be in multiple lines including multiple words as well with example.\n",
        "        2. Surname: The full last name of the individual.\n",
        "        3. Occupation: The full occupation or rank of the individual, including all titles and abbreviations.\n",
        "        4. Date: The latest date associated with the individual. If multiple dates are present, use the most recent. If only one date, use that date.\n",
        "        5. bounding_box:  A dictionary containing *estimated* bounding box coordinates for the *entire text area* of the *valid personnel record*, based on the original image dimensions, but not pixel-perfect accurate as model limitations are known. The coordinates should not include any titles, headings, or non-record text. Consider the text data from the provided list, including 'word', 'coordinates' (in x1,y1&x2,y2 format), and 'confidence' to improve accuracy and provide more detailed information.\n",
        "            - x1: The leftmost pixel, using the original image dimensions, where the *first character of the valid personnel record* begins.\n",
        "            - y1: The topmost pixel, using the original image dimensions, of the *highest character in the valid personnel record*.\n",
        "            - x2: The rightmost pixel, using the original image dimensions, where the *last character of the valid personnel record* ends.\n",
        "            - y2: The bottommost pixel, using the original image dimensions, of the *lowest character in the valid personnel record*.\n",
        "\n",
        "        **Output:**\n",
        "        Present the extracted rows in a JSON format with the following structure:\n",
        "            [\n",
        "            {{\n",
        "                \"Given_Name\": \"Richard Graham\",\n",
        "                \"Surname\": \"Bloomfield\",\n",
        "                \"Occupation\": \"Wing Commander\",\n",
        "                \"Date\": \"1 Aug.19\",\n",
        "                \"bounding_box\": \"x1,y1,x2,y2\",\n",
        "                \"confidence\": \"0.93124869432\"\n",
        "            }},\n",
        "            {{\n",
        "                \"Given_Name\": \"Some Given Name\",\n",
        "                \"Surname\": \"Some Surname\",\n",
        "                \"Occupation\": \"Some Occupation\",\n",
        "                \"Date\": \"1 Jan.22\",\n",
        "                \"bounding_box\": \"x1,y1,x2,y2\",\n",
        "                \"confidence\": \"0.93124869432\"\n",
        "            }}\n",
        "        ]\n",
        "        \"\"\"\n",
        "    active_api_key = api_keys[key_index % len(api_keys)]  # Get the key based on the index and cycle if needed\n",
        "\n",
        "    results, success = generate_gemini_content(prompt, image_path, img_binary, model_name, active_api_key,\n",
        "                                                   logger_instance)\n",
        "    if success:\n",
        "        return results\n",
        "    else:\n",
        "        logger_instance.error(f\"Failed to process {image_path} with current API key\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_image(image_path, vision_path, model_name, debugger_instance, logger_instance, vision_response, api_keys, image_index):\n",
        "    img_binary = cv2.imread(image_path)\n",
        "    if img_binary is None:\n",
        "        logger_instance.warning(f\"Could not read image: {image_path}\")\n",
        "        return None\n",
        "    results = extract_table_rows_with_vision_data_v2(image_path, vision_response, img_binary, model_name, api_keys,\n",
        "                                                   logger_instance, image_index)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_color_image(image_binary):\n",
        "    if len(image_binary.shape) == 3 and image_binary.shape[2] == 3:\n",
        "        return image_binary\n",
        "    else:\n",
        "        img_binary = cv2.cvtColor(image_binary, cv2.COLOR_GRAY2BGR)\n",
        "        return img_binary\n",
        "\n",
        "\n",
        "def convert_thresh_hybrid(image_binary):\n",
        "    img_bin_color = get_color_image(image_binary)\n",
        "    gray = cv2.cvtColor(img_bin_color, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(5, 5))\n",
        "    gray = clahe.apply(gray)\n",
        "    sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "    sharpen = cv2.filter2D(blur, -1, sharpen_kernel)\n",
        "    thresh = cv2.adaptiveThreshold(sharpen, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 5)\n",
        "    return thresh\n",
        "\n",
        "\n",
        "def detect_contours_vertical(thresh, roi=None, kernel=20):\n",
        "    try:\n",
        "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel))\n",
        "        vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
        "        cnts = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "        vertical_contours = []\n",
        "        for c in cnts:\n",
        "            x, y, w, h = cv2.boundingRect(c)\n",
        "            vertical_contour = ([(x, y), (x + w, y), (x + w, y + h), (x, y + h)])\n",
        "            if roi is not None:\n",
        "                roi_x1, roi_y1, roi_x2, roi_y2 = roi\n",
        "                if (x <= roi_x2 and x + w >= roi_x1) and (y <= roi_y2 and y + h >= roi_y1):\n",
        "                    vertical_contours.append(vertical_contour)\n",
        "            else:\n",
        "                vertical_contours.append(vertical_contour)\n",
        "        return vertical_contours\n",
        "    except Exception as ex:\n",
        "        print(f\"Error: {ex}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def draw_vertical_polylines(vcs, image_binary):\n",
        "    sorted_contours = sorted(vcs, key=lambda c: c[0][0])\n",
        "    col_threshold = 10\n",
        "    cols = [[]]\n",
        "    for contour in sorted_contours:\n",
        "        added_to_col = False\n",
        "        for col in cols:\n",
        "            if len(col) == 0:\n",
        "                col.append(contour)\n",
        "                added_to_col = True\n",
        "                break\n",
        "            else:\n",
        "                prev_x = col[-1][0][0]\n",
        "                current_x = contour[0][0]\n",
        "                if abs(prev_x - current_x) <= col_threshold:\n",
        "                    col.append(contour)\n",
        "                    added_to_col = True\n",
        "                    break\n",
        "        if not added_to_col:\n",
        "            cols.append([contour])\n",
        "\n",
        "    vlines = []\n",
        "    height, width, channels = image_binary.shape\n",
        "    vlines_bin = image_binary.copy()\n",
        "    for col in cols:\n",
        "        if len(col) > 0:\n",
        "            min_y = 0\n",
        "            max_y = height\n",
        "            x = col[0][0][0]\n",
        "            vline = [(x, min_y), (x, max_y)]\n",
        "            cv2.line(vlines_bin, (x, min_y), (x, max_y), (255, 0, 0), 1)\n",
        "            vlines.append(vline)\n",
        "\n",
        "    return vlines\n",
        "\n",
        "\n",
        "def image_splitter(image_path, temp_dir, logger, debugger_instance):\n",
        "    image_binary = cv2.imread(image_path)\n",
        "\n",
        "    if image_binary is None:\n",
        "        logger.warning(f\"Could not read image: {image_path}\")\n",
        "        return [], None\n",
        "\n",
        "    height, width, _ = image_binary.shape\n",
        "    thresh = convert_thresh_hybrid(image_binary)\n",
        "    vcs = detect_contours_vertical(thresh=thresh, kernel=100)\n",
        "    vlines = draw_vertical_polylines(vcs, image_binary)\n",
        "    sorted_vlines = sorted(vlines, key=lambda x: x[0])\n",
        "\n",
        "    roi_coordinates = []\n",
        "    prev_x = 0\n",
        "\n",
        "    for i, line in enumerate(sorted_vlines):\n",
        "        x, _ = line[0]\n",
        "        roi_coordinates.append((prev_x, 1, x, height))\n",
        "        prev_x = x\n",
        "        if i == len(vlines) - 1:\n",
        "            roi_coordinates.append((prev_x, 1, width, height))\n",
        "\n",
        "    if len(roi_coordinates) > 0:\n",
        "        temp_image_paths = []\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        for i, roi in enumerate(roi_coordinates):\n",
        "            x1, y1, x2, y2 = roi\n",
        "            cropped_width = x2 - x1\n",
        "\n",
        "            # Only process if width is more than 15% of total width\n",
        "            if cropped_width > (width * 0.15):\n",
        "                cropped_image = image_binary[y1:y2, x1:x2]\n",
        "\n",
        "                if not cropped_image.size == 0:\n",
        "                    temp_filename = f\"{base_name}_part_{i + 1}.jpg\"\n",
        "                    temp_path = os.path.join(temp_dir, temp_filename)\n",
        "                    cv2.imwrite(temp_path, cropped_image)\n",
        "                    temp_image_paths.append(temp_path)\n",
        "                else:\n",
        "                    logger.warning(f\"Empty Cropped Image, skipping the image for {image_path} and ROI {roi}\")\n",
        "            else:\n",
        "                logger.info(f\"Skipping ROI with width {cropped_width} which is less than 15% of total width: {width}\")\n",
        "\n",
        "        return temp_image_paths, image_binary\n",
        "    else:\n",
        "        logger.warning(f\"Vertical segmentation error for {image_path}\")\n",
        "        return [], image_binary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_images_in_folder_v2(image_folder, vision_path, model_name, classifier_path, api_keys,\n",
        "                                 debugger_instance=True, logger_instance=None):\n",
        "    if not logger_instance:\n",
        "        logger_instance = Logger().get_logger()\n",
        "\n",
        "    all_results = []\n",
        "    image_files = [os.path.join(image_folder, filename)\n",
        "                   for filename in os.listdir(image_folder)\n",
        "                   if filename.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        for image_index, image_path in enumerate(image_files):\n",
        "            predicted_class, predicted_label, confidence = predict_image(image_path, classifier_path, class_names)\n",
        "            logger_instance.info(\n",
        "                f'Predicted class for {os.path.basename(image_path)} is {predicted_label} with confidence {confidence}')\n",
        "            print(f\"Processing image: {os.path.basename(image_path)} from folder: {os.path.basename(image_folder)}\")\n",
        "\n",
        "            img_binary = cv2.imread(image_path)\n",
        "            if img_binary is None:\n",
        "                logger_instance.warning(f\"Could not read image: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            gcv = Google_Cloud_Vision(logger=logger_instance)\n",
        "            gcv.set_debug_mood(debugger_instance)\n",
        "            gcv.set_gcv_key(vision_path)\n",
        "            gcv.set_input_file(image_path)\n",
        "\n",
        "            vision_response = gcv.google_cloud_vision_response_with_word_wise_coordinates(img_binary,\n",
        "                                                                                           language_hints=['en'])\n",
        "            logger_instance.info(f'Vision Done. Gemini on process {os.path.basename(image_path)}')\n",
        "\n",
        "            if predicted_label == 'col1':\n",
        "                logger_instance.info(\n",
        "                    f\"This {os.path.basename(image_path)} identified as {predicted_label}. So splitting in progress\")\n",
        "                temp_image_paths, image_binary = image_splitter(image_path, temp_dir, logger_instance,\n",
        "                                                                debugger_instance)\n",
        "                if len(temp_image_paths) > 0:\n",
        "                    for temp_path in temp_image_paths:\n",
        "                        results = process_image(temp_path, vision_path, model_name, debugger_instance,\n",
        "                                                logger_instance, vision_response, api_keys, image_index)\n",
        "                        if results:\n",
        "                            all_results.extend(results)\n",
        "                elif image_binary is not None:\n",
        "                   results = process_image(image_path, vision_path, model_name, debugger_instance,\n",
        "                                            logger_instance, vision_response, api_keys, image_index)\n",
        "                   if results:\n",
        "                        all_results.extend(results)\n",
        "\n",
        "            elif predicted_label == 'col0':\n",
        "                logger_instance.info(\n",
        "                    f\"This {os.path.basename(image_path)} identified as {predicted_label}. No splitting required\")\n",
        "                results = process_image(image_path, vision_path, model_name, debugger_instance, logger_instance,\n",
        "                                        vision_response, api_keys, image_index)\n",
        "                if results:\n",
        "                    all_results.extend(results)\n",
        "            else:\n",
        "                logger_instance.warning(f\"Skipping image {image_path} due to unknown classification {predicted_label}\")\n",
        "\n",
        "            time.sleep(5) # Introduce the 5 seconds delay\n",
        "\n",
        "    global failed_key_info\n",
        "    if failed_key_info:\n",
        "        logger_instance.warning(f\"Failed keys: {failed_key_info}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "def transform_records(records):\n",
        "    def parse_date(date_str):\n",
        "        if not date_str:\n",
        "            return None, None, None\n",
        "\n",
        "        date_str = date_str.replace('.', '')\n",
        "        import re\n",
        "\n",
        "        # Updated patterns to handle both formats\n",
        "        patterns = [\n",
        "            r'(\\d{1,2})\\s*([A-Za-z]+)\\s*(\\d{2})?',  # Handles \"1 Sept\" and \"1 Sept 23\"\n",
        "            r'(\\d{1,2})([A-Za-z]+)(\\d{2})?'  # Handles \"1Sept\" and \"1Sept23\"\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, date_str)\n",
        "            if match:\n",
        "                day, month, year = match.groups()\n",
        "                day = day.strip()\n",
        "                month = month.strip()\n",
        "                year = '19' + year.strip() if year else None\n",
        "                return day, month, year\n",
        "\n",
        "        return None, None, None\n",
        "\n",
        "    transformed_records = []\n",
        "\n",
        "    for record in records:\n",
        "        transformed_record = record.copy()\n",
        "\n",
        "        # Parse the date and add components\n",
        "        day, month, year = parse_date(record['Date'])\n",
        "        transformed_record['Day'] = day\n",
        "        transformed_record['Month'] = month\n",
        "        transformed_record['Year'] = year\n",
        "\n",
        "        # Remove the original Date field\n",
        "        del transformed_record['Date']\n",
        "\n",
        "        transformed_records.append(transformed_record)\n",
        "\n",
        "    return transformed_records\n",
        "\n",
        "\n",
        "def correct_month_abbreviations(records):\n",
        "    corrected_records = []\n",
        "    for record in records:\n",
        "        corrected_record = record.copy()\n",
        "\n",
        "        # Only correct 'ct' to 'Oct'\n",
        "        if record['Month'] == 'ct':\n",
        "            corrected_record['Month'] = 'Oct'\n",
        "\n",
        "        corrected_records.append(corrected_record)\n",
        "\n",
        "    return corrected_records\n",
        "\n",
        "\n",
        "def transform_none_to_space(data):\n",
        "    for item in data:\n",
        "        for key in item:\n",
        "            if item[key] is None:\n",
        "                item[key] = ' '\n",
        "    return data\n",
        "\n",
        "\n",
        "def clean_occupation_field(data):\n",
        "    for item in data:\n",
        "        occupation = item['Occupation']\n",
        "\n",
        "        # Split Given_Name into parts and handle each part\n",
        "        given_name_parts = item['Given_Name'].strip().replace('.', ' ').split()\n",
        "        surname = item['Surname'].strip()\n",
        "\n",
        "        # Create a working copy of occupation\n",
        "        cleaned_occupation = occupation\n",
        "\n",
        "        # Remove each part of Given_Name if found\n",
        "        for part in given_name_parts:\n",
        "            cleaned_occupation = cleaned_occupation.replace(part, '').strip()\n",
        "\n",
        "        # Remove surname\n",
        "        cleaned_occupation = cleaned_occupation.replace(surname, '').strip()\n",
        "\n",
        "        # Clean up any remaining artifacts\n",
        "        cleaned_occupation = cleaned_occupation.strip(' ,.').strip()\n",
        "\n",
        "        # Update the occupation field\n",
        "        item['Occupation'] = cleaned_occupation\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def process_data(input_data):\n",
        "    # First transform None values to spaces\n",
        "    data = transform_none_to_space(input_data)\n",
        "    # Then clean occupation fields\n",
        "    data = clean_occupation_field(data)\n",
        "    return data\n",
        "\n",
        "\n",
        "def process_names_v2(input_data):\n",
        "    processed_data = []\n",
        "\n",
        "    for record in input_data:\n",
        "        new_record = record.copy()\n",
        "\n",
        "        # Handle cases where name contains comma\n",
        "        if ',' in record['Given_Name']:\n",
        "            # Split by comma first\n",
        "            surname, given_parts = record['Given_Name'].split(',', 1)\n",
        "            new_record['Surname'] = surname.strip()\n",
        "            new_record['Given_Name'] = given_parts.strip()\n",
        "        else:\n",
        "            # Original logic for when no comma exists\n",
        "            name_parts = record['Given_Name'].split()\n",
        "\n",
        "            if record['Surname'] is None or record['Surname'].strip() == '':\n",
        "                if name_parts:  # Check if name_parts is not empty\n",
        "                    new_record['Surname'] = name_parts[-1]\n",
        "                    new_record['Given_Name'] = ' '.join(name_parts[:-1])\n",
        "                else:\n",
        "                    new_record['Surname'] = ''\n",
        "                    new_record['Given_Name'] = ''\n",
        "            else:\n",
        "                surname = record['Surname']\n",
        "                filtered_parts = [part for part in name_parts if part != surname]\n",
        "                new_record['Given_Name'] = ' '.join(filtered_parts)\n",
        "\n",
        "        processed_data.append(new_record)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "def add_conf_Prect(input_records):\n",
        "    transformed_records = []\n",
        "\n",
        "    for record in input_records:\n",
        "        new_record = {}\n",
        "\n",
        "        # Fields to process\n",
        "        fields = ['Given_Name', 'Surname', 'Occupation', 'Day', 'Month', 'Year']\n",
        "\n",
        "        for field in fields:\n",
        "            # Add the main field\n",
        "            new_record[field] = record[field]\n",
        "            # Add confidence\n",
        "            new_record[f'{field}_conf'] = record['confidence']\n",
        "            # Add bounding box\n",
        "            new_record[f'{field}_PRect'] = record['bounding_box']\n",
        "\n",
        "        # Add Image field\n",
        "        new_record['Image'] = record['Image'].split('.jpg')[0]\n",
        "\n",
        "        transformed_records.append(new_record)\n",
        "\n",
        "    return transformed_records\n",
        "\n",
        "\n",
        "def add_orig_hwr(input_records):\n",
        "    base_fields = ['Given_Name', 'Surname', 'Occupation', 'Day', 'Month', 'Year']\n",
        "    transformed_records = []\n",
        "\n",
        "    for record in input_records:\n",
        "        new_record = {}\n",
        "\n",
        "        # Handle the base fields that need _orig and _hwr suffixes\n",
        "        for field in base_fields:\n",
        "            if field in record:\n",
        "                new_record[f\"{field}_orig\"] = record[field]\n",
        "                new_record[f\"{field}_hwr\"] = record[field]\n",
        "\n",
        "                # Copy the associated confidence and PRect fields\n",
        "                if f\"{field}_conf\" in record:\n",
        "                    new_record[f\"{field}_conf\"] = record[f\"{field}_conf\"]\n",
        "                if f\"{field}_PRect\" in record:\n",
        "                    new_record[f\"{field}_PRect\"] = record[f\"{field}_PRect\"]\n",
        "\n",
        "        # Copy the Image field as is\n",
        "        if 'Image' in record:\n",
        "            new_record['Image'] = record['Image']\n",
        "\n",
        "        transformed_records.append(new_record)\n",
        "\n",
        "    return transformed_records\n",
        "\n",
        "\n",
        "def add_missing_keys(data_list, header, batch_name):\n",
        "    \"\"\"\n",
        "    Add missing keys from the header to each dictionary in the input list.\n",
        "    Sets ImageType to 'Graduation_List' and Batch to the provided batch_name.\n",
        "\n",
        "    Parameters:\n",
        "    data_list (list): A list of dictionaries containing data.\n",
        "    header (list): A list of all expected keys.\n",
        "    batch_name (str): The batch name to be added.\n",
        "\n",
        "    Returns:\n",
        "    list: Updated list of dictionaries with missing keys added in the correct order.\n",
        "    \"\"\"\n",
        "    updated_list = []\n",
        "    for data in data_list:\n",
        "        ordered_data = {key: data.get(key, '') for key in header}\n",
        "        ordered_data['ImageType'] = 'Graduation_List'\n",
        "        ordered_data['Batch'] = os.path.basename(batch_name)\n",
        "        updated_list.append(ordered_data)\n",
        "    return updated_list\n",
        "\n",
        "\n",
        "header = [\n",
        "    'ImageType', 'Batch', 'Image', 'ZoneUserID', 'ZoneDate', 'ImageRotation',\n",
        "    'Page_orig', 'Page_hwr', 'Page_conf', 'Page_PRect',\n",
        "    'Occupation_orig', 'Occupation_hwr', 'Occupation_conf', 'Occupation_PRect',\n",
        "    'Military Branch_orig', 'Military Branch_hwr', 'Military Branch_conf', 'Military Branch_PRect',\n",
        "    'Given_Name_orig', 'Given_Name_hwr', 'Given_Name_conf', 'Given_Name_PRect',\n",
        "    'Surname_orig', 'Surname_hwr', 'Surname_conf', 'Surname_PRect',\n",
        "    'Rank_orig', 'Rank_hwr', 'Rank_conf', 'Rank_PRect',\n",
        "    'Day_orig', 'Day_hwr', 'Day_conf', 'Day_PRect',\n",
        "    'Month_orig', 'Month_hwr', 'Month_conf', 'Month_PRect',\n",
        "    'Year_orig', 'Year_hwr', 'Year_conf', 'Year_PRect',\n",
        "    'Organization_orig', 'Organization_hwr', 'Organization_conf', 'Organization_PRect'\n",
        "]\n",
        "\n",
        "def write_to_pipe_delimited_file(list_of_dicts, filename=None):\n",
        "    try:\n",
        "        if not list_of_dicts:\n",
        "            return \"\"\n",
        "        headers = list(list_of_dicts[0].keys())\n",
        "        header_line = '|'.join(headers)\n",
        "        data_lines = []\n",
        "        for entry in list_of_dicts:\n",
        "            values = []\n",
        "            for key in headers:\n",
        "                try:\n",
        "                    value = str(entry.get(key, ''))\n",
        "                    values.append(value)\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred while processing key '{key}' for entry: {str(e)}\")\n",
        "                    values.append('')\n",
        "            data_lines.append('|'.join(values))\n",
        "        result = f\"{header_line}\\n\"\n",
        "        result += '\\n'.join(data_lines)\n",
        "        if filename:\n",
        "            try:\n",
        "                with open(filename, 'w', encoding='utf-8') as file:\n",
        "                    file.write(result)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while writing to file '{filename}': {str(e)}\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in write_to_pipe_delimited_file: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def organize_images_into_folders(image_folder, images_per_folder=20):\n",
        "    \"\"\"\n",
        "    Organizes images from a given folder into subfolders, each containing a specified\n",
        "    number of images.\n",
        "\n",
        "    Args:\n",
        "        image_folder (str): The path to the folder containing the images.\n",
        "        images_per_folder (int, optional): The number of images to include in each subfolder.\n",
        "            Defaults to 20.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(image_folder):\n",
        "        print(f\"Error: Image folder not found at '{image_folder}'\")\n",
        "        return\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))\n",
        "                   and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    if num_images == 0:\n",
        "        print(f\"Error: No images found in folder '{image_folder}'\")\n",
        "        return\n",
        "\n",
        "    num_folders = (num_images + images_per_folder - 1) // images_per_folder\n",
        "\n",
        "    print(f\"Organizing {num_images} images into {num_folders} folders...\")\n",
        "\n",
        "    for folder_num in range(num_folders):\n",
        "        folder_name = f\"{os.path.basename(image_folder)}_part_{folder_num + 1}\"  # Modified folder naming\n",
        "        new_folder_path = os.path.join(image_folder, folder_name)\n",
        "        os.makedirs(new_folder_path, exist_ok=True)  # Create folder if it doesn't exist\n",
        "\n",
        "        start_index = folder_num * images_per_folder\n",
        "        end_index = min((folder_num + 1) * images_per_folder, num_images)\n",
        "\n",
        "        for i in range(start_index, end_index):\n",
        "            source_path = os.path.join(image_folder, image_files[i])\n",
        "            destination_path = os.path.join(new_folder_path, image_files[i])\n",
        "            shutil.move(source_path, destination_path)\n",
        "\n",
        "    print(\"Image organization complete!\")\n",
        "\n",
        "def main(image_base_folder):\n",
        "    start_time = time.time()\n",
        "    print(\"Processing Starts.........!!!!!!\")\n",
        "\n",
        "    output_folder = \"/content/subfolder_failed_output\"  # set output folder\n",
        "    os.makedirs(output_folder, exist_ok=True)  # create the folder if it doesn't exist\n",
        "\n",
        "    # Get subfolders inside the main image folder\n",
        "    subfolders = [f.path for f in os.scandir(image_base_folder) if f.is_dir()]\n",
        "\n",
        "    for folder in subfolders:\n",
        "        print(f\"Processing folder: {folder}\")\n",
        "\n",
        "        results = process_images_in_folder_v2(folder, vision_path, model_name, classifier_path, api_keys)\n",
        "        transformed_records = transform_records(results)\n",
        "        corrected_output = correct_month_abbreviations(transformed_records)\n",
        "        processed_data = process_data(corrected_output)\n",
        "        processed_names = process_names_v2(processed_data)\n",
        "        added_conf_prect = add_conf_Prect(processed_names)\n",
        "        added_orig_hwr = add_orig_hwr(added_conf_prect)\n",
        "        added_missing_keys = add_missing_keys(added_orig_hwr, header, folder)\n",
        "\n",
        "        # Create a file based on the subfolder name in the output folder\n",
        "        file_name = os.path.join(output_folder, f\"{os.path.basename(folder)}.txt\")\n",
        "        write_to_pipe_delimited_file(added_missing_keys, file_name)\n",
        "\n",
        "        print(f\"Output has been saved to: {file_name}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"\\nProcessing Ends....!!!!!!!\")\n",
        "\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"\\n\")\n",
        "    print(f\"It took {elapsed_time} seconds to complete!!!!!!\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_base_folder = \"/content/image540\"  # change this to your main image folder\n",
        "\n",
        "    # First organize the images into subfolders\n",
        "    organize_images_into_folders(image_base_folder, images_per_folder=3)\n",
        "\n",
        "    # Then process the images in subfolders\n",
        "    main(image_base_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omq0aYy3SHhO"
      },
      "outputs": [],
      "source": [
        "# code to combine  pipe delimited text files\n",
        "import os\n",
        "\n",
        "def combine_text_files(input_dir, output_file):\n",
        "    \"\"\"\n",
        "    Combines multiple pipe-delimited text files into a single output file.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing the input files.\n",
        "        output_file (str): Path to the desired output file.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        header_written = False  # Flag to track if the header has been written\n",
        "\n",
        "        for filename in os.listdir(input_dir):\n",
        "            if filename.endswith(\".txt\"):  # Process only .txt files\n",
        "                filepath = os.path.join(input_dir, filename)\n",
        "                with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "                    for i, line in enumerate(infile):\n",
        "                        line = line.strip() #remove leading/trailing whitespace\n",
        "                        if not line: #skip empty lines\n",
        "                            continue\n",
        "\n",
        "                        if not header_written:\n",
        "                            outfile.write(line + \"\\n\")\n",
        "                            header_written = True  # Write the header once from first file\n",
        "                        elif i > 0 :\n",
        "                            outfile.write(line + \"\\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    input_directory = \"/content/subfolder_failed_output\"  # Replace with the actual directory\n",
        "    output_filename = \"failed_images_with_540.txt\"  # Replace with the desired output file name\n",
        "\n",
        "    combine_text_files(input_directory, output_filename)\n",
        "    print(f\"Files combined successfully into: {output_filename}\")\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS_8gyyISfsJ"
      },
      "outputs": [],
      "source": [
        "# code to transform pipe delimited text file to csv\n",
        "import csv\n",
        "\n",
        "def convert_pipe_to_csv(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Converts a pipe-delimited text file to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input pipe-delimited file.\n",
        "        output_file (str): Path to the desired output CSV file.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
        "         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
        "\n",
        "        reader = csv.reader(infile, delimiter='|', skipinitialspace=True)\n",
        "        writer = csv.writer(outfile)\n",
        "\n",
        "        for row in reader:\n",
        "            #remove leading/trailing white space from row values\n",
        "            cleaned_row = [value.strip() for value in row]\n",
        "            writer.writerow(cleaned_row)\n",
        "\n",
        "def main():\n",
        "    input_filename = \"/content/failed_images_with_540.txt\"  # Replace with your input file\n",
        "    output_filename = \"failed_images_with_540.csv\" # Replace with your desired output file name\n",
        "\n",
        "    convert_pipe_to_csv(input_filename, output_filename)\n",
        "    print(f\"File converted successfully to: {output_filename}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aAOsiDj9SYt",
        "outputId": "67eac0b2-99df-4e93-c930-aa0c65ea03ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File converted successfully to: failed_images_with_540_final.txt\n"
          ]
        }
      ],
      "source": [
        "# code to transform csv to pipe delimited text file\n",
        "\n",
        "import csv\n",
        "\n",
        "def convert_csv_to_pipe(input_file, output_file):\n",
        "    \"\"\"\n",
        "    Converts a CSV file to a pipe-delimited text file.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input CSV file.\n",
        "        output_file (str): Path to the desired output pipe-delimited file.\n",
        "    \"\"\"\n",
        "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
        "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "        reader = csv.reader(infile)\n",
        "        writer = csv.writer(outfile, delimiter='|')\n",
        "\n",
        "        for row in reader:\n",
        "            # remove leading/trailing white space from row values\n",
        "            cleaned_row = [value.strip() for value in row]\n",
        "            writer.writerow(cleaned_row)\n",
        "\n",
        "def main():\n",
        "    input_filename = \"failed_images.csv\"  # Replace with your input file\n",
        "    output_filename = \"failed_images_with_540_final.txt\" # Replace with your desired output file name\n",
        "\n",
        "    convert_csv_to_pipe(input_filename, output_filename)\n",
        "    print(f\"File converted successfully to: {output_filename}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFnY4-qIncLb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
